import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# ===========================
# åŸºæœ¬è¨­å®š
# ===========================
st.set_page_config(page_title="NPBé¸æ‰‹å¹´ä¿¸äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ", page_icon="âš¾", layout="centered")

try:
    import japanize_matplotlib
    plt.rcParams["font.family"] = "IPAexGothic"
except ImportError:
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans','Arial Unicode MS','sans-serif']


# ===========================
# CSVèª­ã¿è¾¼ã¿ï¼ˆmergedç‰ˆï¼‰
# ===========================
@st.cache_data
def load_data():
    try:
        merged_df = pd.read_csv("data/merged_stats_salary_age.csv")
        titles_df = pd.read_csv("data/titles_2023&2024&2025.csv")
        return merged_df, titles_df, True
    except FileNotFoundError:
        return None, None, False


merged_df, titles_df, data_loaded = load_data()


# ===========================
# å¹´ä¿¸æ¸›é¡åˆ¶é™
# ===========================
def calculate_salary_limit(previous_salary):
    if previous_salary >= 100_000_000:
        min_salary = previous_salary * 0.60
        reduction_rate = 0.40
    else:
        min_salary = previous_salary * 0.75
        reduction_rate = 0.25
    return min_salary, reduction_rate


def check_salary_reduction_limit(predicted, previous):
    min_salary, reduction_rate = calculate_salary_limit(previous)
    return predicted < min_salary, min_salary, reduction_rate


# ===========================
# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆmerged ã«ã‚¿ã‚¤ãƒˆãƒ«åˆ—è¿½åŠ ï¼‰
# ===========================
@st.cache_data
def prepare_data(merged_df, titles_df):

    # ã‚¿ã‚¤ãƒˆãƒ«é›†è¨ˆ
    titles_df_clean = titles_df.dropna(subset=['é¸æ‰‹å'])
    title_summary = titles_df_clean.groupby(
        ['é¸æ‰‹å', 'å¹´åº¦']
    ).size().reset_index(name='ã‚¿ã‚¤ãƒˆãƒ«æ•°')

    # mergedã¨çµåˆ
    merged_df = pd.merge(
        merged_df,
        title_summary,
        on=['é¸æ‰‹å', 'å¹´åº¦'],
        how='left'
    )
    merged_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'] = merged_df['ã‚¿ã‚¤ãƒˆãƒ«æ•°'].fillna(0)

    # stats_all_with_titles ã¨ã—ã¦ãã®ã¾ã¾åˆ©ç”¨
    stats_all_with_titles = merged_df.copy()

    # salary_long ã‚’ merged ã‹ã‚‰ç”Ÿæˆ
    salary_long = merged_df[['é¸æ‰‹å', 'å¹´åº¦', 'å¹´ä¿¸_å††']].dropna()

    return merged_df, stats_all_with_titles, salary_long


# ===========================
# ãƒ¢ãƒ‡ãƒ«è¨“ç·´ï¼ˆå¯¾æ•°å¤‰æ›ï¼‰
# ===========================
@st.cache_resource
def train_models(merged_df):

    feature_cols = [
        'è©¦åˆ','æ‰“å¸­','æ‰“æ•°','å¾—ç‚¹','å®‰æ‰“','äºŒå¡æ‰“','ä¸‰å¡æ‰“','æœ¬å¡æ‰“',
        'å¡æ‰“','æ‰“ç‚¹','ç›—å¡','ç›—å¡åˆº','å››çƒ','æ­»çƒ','ä¸‰æŒ¯','ä½µæ®ºæ‰“',
        'æ‰“ç‡','å‡ºå¡ç‡','é•·æ‰“ç‡','çŠ æ‰“','çŠ é£›','ã‚¿ã‚¤ãƒˆãƒ«æ•°','å¹´é½¢'
    ]

    ml_df = merged_df.copy()
    ml_df = ml_df.dropna(subset=feature_cols + ['å¹´ä¿¸_å††'])

    X = ml_df[feature_cols]
    y = ml_df['å¹´ä¿¸_å††']

    y_log = np.log1p(y)

    X_train, X_test, y_train_log, y_test_log = train_test_split(
        X, y_log, test_size=0.2, random_state=42
    )

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    models = {
        'ç·šå½¢å›å¸°': LinearRegression(),
        'ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ': RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42),
        'å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°': GradientBoostingRegressor(n_estimators=200, max_depth=5)
    }

    results = {}

    for name, model in models.items():
        if name == 'ç·šå½¢å›å¸°':
            model.fit(X_train_scaled, y_train_log)
            y_pred_log = model.predict(X_test_scaled)
        else:
            model.fit(X_train, y_train_log)
            y_pred_log = model.predict(X_test)

        y_pred = np.expm1(y_pred_log)
        y_test_original = np.expm1(y_test_log)

        mae = mean_absolute_error(y_test_original, y_pred)
        r2 = r2_score(y_test_original, y_pred)

        results[name] = {'model': model, 'MAE': mae, 'R2': r2}

    best_model_name = max(results.items(), key=lambda x: x[1]['R2'])[0]
    best_model = results[best_model_name]['model']

    return best_model, best_model_name, scaler, feature_cols, results, ml_df


# ===========================
# ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
# ===========================
if data_loaded:

    merged_df, stats_all_with_titles, salary_long = prepare_data(merged_df, titles_df)

    best_model, best_model_name, scaler, feature_cols, results, ml_df = train_models(merged_df)


# ===========================
# UI
# ===========================
st.title("âš¾ NPBé¸æ‰‹å¹´ä¿¸äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ï¼ˆMergedç‰ˆï¼‰")
st.markdown("---")

menu = st.sidebar.radio(
    "ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’é¸æŠ",
    ["ğŸ  ãƒ›ãƒ¼ãƒ ","ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬","ğŸ“Š è¤‡æ•°é¸æ‰‹æ¯”è¼ƒ","ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½","ğŸ“‰ è¦å› åˆ†æ"]
)


# ===========================
# ãƒ›ãƒ¼ãƒ 
# ===========================
if menu == "ğŸ  ãƒ›ãƒ¼ãƒ ":

    col1,col2,col3 = st.columns(3)
    with col1:
        st.metric("ãƒ‡ãƒ¼ã‚¿æ•°", len(ml_df))
    with col2:
        st.metric("ãƒ¢ãƒ‡ãƒ«", best_model_name)
    with col3:
        st.metric("RÂ²", f"{results[best_model_name]['R2']:.4f}")

    st.info("merged CSV ã«å¯¾å¿œã—ãŸæœ€æ–°ç‰ˆã§ã™")


# ===========================
# ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬
# ===========================
elif menu == "ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬":

    st.header("ğŸ” é¸æ‰‹æ¤œç´¢ãƒ»äºˆæ¸¬")

    available_players = stats_all_with_titles['é¸æ‰‹å'].unique()
    available_players = sorted(available_players)

    selected_player = st.selectbox("é¸æ‰‹åã‚’é¸æŠ", available_players)

    predict_year = st.slider("äºˆæ¸¬å¹´åº¦", 2024, 2026, 2025)

    if st.button("äºˆæ¸¬å®Ÿè¡Œ"):

        stats_year = predict_year - 1
        
        player_stats = stats_all_with_titles[
            (stats_all_with_titles['é¸æ‰‹å']==selected_player) &
            (stats_all_with_titles['å¹´åº¦']==stats_year)
        ]

        if player_stats.empty:
            st.error(f"{stats_year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ãªã—")
        else:
            row = player_stats.iloc[0]
            features = row[feature_cols].values.reshape(1,-1)

            if best_model_name=="ç·šå½¢å›å¸°":
                features_scaled = scaler.transform(features)
                pred_log = best_model.predict(features_scaled)[0]
            else:
                pred_log = best_model.predict(features)[0]

            predicted_salary = np.expm1(pred_log)

            # å‰å¹´å¹´ä¿¸
            ps = salary_long[
                (salary_long['é¸æ‰‹å']==selected_player)&
                (salary_long['å¹´åº¦']==stats_year)
            ]
            previous_salary = ps['å¹´ä¿¸_å††'].values[0] if not ps.empty else None

            # æ¸›é¡åˆ¶é™å‡¦ç†
            display_salary = predicted_salary
            if previous_salary is not None:
                is_limit, min_salary, rate = check_salary_reduction_limit(predicted_salary, previous_salary)
                if is_limit:
                    display_salary = min_salary
                    st.warning(f"âš ï¸ æ¸›é¡åˆ¶é™ã«ã‚ˆã‚Š {min_salary/1e6:.1f}ç™¾ä¸‡å†† ã«èª¿æ•´")

            st.success("äºˆæ¸¬å®Œäº†ï¼")

            col1, col2 = st.columns(2)
            col1.metric("äºˆæ¸¬å¹´ä¿¸", f"{display_salary/1e6:.1f}ç™¾ä¸‡å††")
            if previous_salary:
                col2.metric("å‰å¹´å¹´ä¿¸", f"{previous_salary/1e6:.1f}ç™¾ä¸‡å††")

            # ãƒ¬ãƒ¼ãƒ€ãƒ¼
            st.markdown("---")
            st.subheader(f"{stats_year}å¹´ æˆç¸¾ãƒ¬ãƒ¼ãƒ€ãƒ¼")

            radar_stats = {
                'æ‰“ç‡': row['æ‰“ç‡']/0.35,
                'å‡ºå¡ç‡': row['å‡ºå¡ç‡']/0.45,
                'é•·æ‰“ç‡': row['é•·æ‰“ç‡']/0.60,
                'æœ¬å¡æ‰“': min(row['æœ¬å¡æ‰“']/40,1),
                'æ‰“ç‚¹': min(row['æ‰“ç‚¹']/100,1),
                'ç›—å¡': min(row['ç›—å¡']/40,1)
            }

            categories = list(radar_stats.keys())
            values = list(radar_stats.values()) + [list(radar_stats.values())[0]]

            angles = np.linspace(0,2*np.pi,len(categories),endpoint=False).tolist()
            angles += angles[:1]

            fig, ax = plt.subplots(figsize=(6,6), subplot_kw=dict(projection='polar'))
            ax.plot(angles, values,'o-', linewidth=2)
            ax.fill(angles, values,alpha=0.25)
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(categories)
            st.pyplot(fig)
            plt.close(fig)


# ===========================
# ğŸ“Š è¤‡æ•°é¸æ‰‹æ¯”è¼ƒ
# ===========================
elif menu == "ğŸ“Š è¤‡æ•°é¸æ‰‹æ¯”è¼ƒ":

    st.header("ğŸ“Š è¤‡æ•°é¸æ‰‹æ¯”è¼ƒ")

    available_players = sorted(stats_all_with_titles['é¸æ‰‹å'].unique())

    selected_players = st.multiselect("æ¯”è¼ƒé¸æ‰‹ï¼ˆæœ€å¤§5ï¼‰", available_players)

    if len(selected_players)>=2 and st.button("æ¯”è¼ƒå®Ÿè¡Œ"):

        results_list = []

        for p in selected_players:
            row = stats_all_with_titles[
                (stats_all_with_titles['é¸æ‰‹å']==p)&
                (stats_all_with_titles['å¹´åº¦']==2024)
            ]
            if row.empty: continue
            row = row.iloc[0]

            features = row[feature_cols].values.reshape(1,-1)

            if best_model_name=="ç·šå½¢å›å¸°":
                pred_log = best_model.predict(scaler.transform(features))[0]
            else:
                pred_log = best_model.predict(features)[0]

            pred = np.expm1(pred_log)

            prev = salary_long[
                (salary_long['é¸æ‰‹å']==p)&(salary_long['å¹´åº¦']==2024)
            ]
            prev_salary = prev['å¹´ä¿¸_å††'].values[0] if not prev.empty else None

            disp = pred
            is_limit=False
            if prev_salary is not None:
                is_limit, ms, rate = check_salary_reduction_limit(pred, prev_salary)
                if is_limit:
                    disp = ms

            results_list.append({
                "é¸æ‰‹å":p,
                "äºˆæ¸¬ï¼ˆåˆ¶é™å‰ï¼‰": pred/1e6,
                "äºˆæ¸¬ï¼ˆåˆ¶é™å¾Œï¼‰": disp/1e6,
                "å‰å¹´å¹´ä¿¸": prev_salary/1e6 if prev_salary else None,
                "æœ¬å¡æ‰“":row["æœ¬å¡æ‰“"],
                "æ‰“ç‚¹":row["æ‰“ç‚¹"],
                "æ‰“ç‡":row["æ‰“ç‡"],
            })

        df_results = pd.DataFrame(results_list)
        st.dataframe(df_results, use_container_width=True)


# ===========================
# ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
# ===========================
elif menu == "ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½":

    st.header("ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½")

    model_rows = []
    for name, res in results.items():
        model_rows.append({
            "ãƒ¢ãƒ‡ãƒ«": name,
            "MAEï¼ˆç™¾ä¸‡å††ï¼‰": res["MAE"]/1e6,
            "RÂ²": res["R2"],
        })

    st.dataframe(pd.DataFrame(model_rows))


# ===========================
# ğŸ“‰ è¦å› åˆ†æ
# ===========================
elif menu == "ğŸ“‰ è¦å› åˆ†æ":

    st.header("ğŸ“‰ è¦å› åˆ†æ")

    corr = ml_df[['æ‰“ç‡','æœ¬å¡æ‰“','æ‰“ç‚¹','å‡ºå¡ç‡','é•·æ‰“ç‡','ã‚¿ã‚¤ãƒˆãƒ«æ•°','å¹´é½¢','å¹´ä¿¸_å††']].corr()['å¹´ä¿¸_å††']
    st.write(corr)


# ===========================
# çµ‚ã‚ã‚Š
# ===========================
st.markdown("---")
st.caption("NPB å¹´ä¿¸äºˆæ¸¬ï¼ˆmerged CSV å¯¾å¿œç‰ˆï¼‰")
